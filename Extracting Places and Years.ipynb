{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2e602e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import redis\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24d6fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5857f89",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480265dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35ffdb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 10 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "- All prompts end with suffix `.\\n\\n###\\n\\n`\n",
      "- All prompts start with prefix `A `\n",
      "- All completions end with suffix `\\n###`\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `sampletables_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"sampletables_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `.\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n###\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 2.58 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "# !openai tools fine_tunes.prepare_data -f sampletables.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86d1e5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.3k/12.3k [00:00<00:00, 9.97Mit/s]\n",
      "Uploaded file from sampletables_prepared.jsonl: file-0C8gVJ7ne33AMbaivGI13DoZ\n",
      "Created fine-tune: ft-40GXzPbAP9lSURRU5wyloxmR\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-05-02 21:46:11] Created fine-tune: ft-40GXzPbAP9lSURRU5wyloxmR\n",
      "[2023-05-02 21:46:25] Fine-tune costs $0.00\n",
      "[2023-05-02 21:46:26] Fine-tune enqueued. Queue number: 0\n",
      "[2023-05-02 21:46:28] Fine-tune started\n",
      "[2023-05-02 21:46:42] Completed epoch 1/4\n",
      "[2023-05-02 21:46:44] Completed epoch 2/4\n",
      "[2023-05-02 21:46:45] Completed epoch 3/4\n",
      "[2023-05-02 21:46:47] Completed epoch 4/4\n",
      "[2023-05-02 21:47:09] Uploaded model: ada:ft-personal-2023-05-03-04-47-09\n",
      "[2023-05-02 21:47:10] Uploaded result file: file-GrKGDt99szC7rnUhkqID5FVM\n",
      "[2023-05-02 21:47:10] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded ðŸŽ‰\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m ada:ft-personal-2023-05-03-04-47-09 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "# !openai api fine_tunes.create -t \"sampletables_prepared.jsonl\" -m ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7eab91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = 'ada:ft-personal-2023-05-03-04-47-09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42092789",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_pre = 'I am tracking the person\\'s location throughout his life. Please generate a table of time and location. The time should be an inferred time period. The time period can be inferred based on the event described in the sentence, for example, attending a university usually takes 4 years, so you can infer that the person starts staying at the location 4 years prior to graduation.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68d17023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usCongressBioId</th>\n",
       "      <th>profileText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W000374</td>\n",
       "      <td>A Representative from Kansas; born near Fairfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L000226</td>\n",
       "      <td>A Representative from Florida; born in Selma, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F000260</td>\n",
       "      <td>A Representative from Michigan, Vice President...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M000777</td>\n",
       "      <td>A Representative and a Senator from Texas; bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W000724</td>\n",
       "      <td>A Representative from Ohio; born in Johnstown,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  usCongressBioId                                        profileText\n",
       "0         W000374  A Representative from Kansas; born near Fairfi...\n",
       "1         L000226  A Representative from Florida; born in Selma, ...\n",
       "2         F000260  A Representative from Michigan, Vice President...\n",
       "3         M000777  A Representative and a Senator from Texas; bor...\n",
       "4         W000724  A Representative from Ohio; born in Johnstown,..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('results/bioguide.csv')\n",
    "df = df[['usCongressBioId', 'profileText']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "854a7dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usCongressBioId</th>\n",
       "      <th>profileText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td>K000004</td>\n",
       "      <td>A Delegate from the Territory of Hawaii; born ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>J000157</td>\n",
       "      <td>A Representative from California; born in Waus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>B000901</td>\n",
       "      <td>A Representative from New York; born in Charlt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9958</th>\n",
       "      <td>B000948</td>\n",
       "      <td>A Representative from Virginia and from West V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>D000112</td>\n",
       "      <td>A Senator from Arkansas; born near Richmond, L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8334</th>\n",
       "      <td>J000153</td>\n",
       "      <td>A Representative from Ohio; born near Dunganno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10174</th>\n",
       "      <td>P000015</td>\n",
       "      <td>A Representative from Rhode Island; born in Gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>D000030</td>\n",
       "      <td>A Senator from Missouri; born in St. Louis, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>G000423</td>\n",
       "      <td>A Representative from Kentucky; born in 1818; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8346</th>\n",
       "      <td>V000118</td>\n",
       "      <td>A Representative from California; born in Otta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      usCongressBioId                                        profileText\n",
       "7812          K000004  A Delegate from the Territory of Hawaii; born ...\n",
       "3034          J000157  A Representative from California; born in Waus...\n",
       "4020          B000901  A Representative from New York; born in Charlt...\n",
       "9958          B000948  A Representative from Virginia and from West V...\n",
       "4601          D000112  A Senator from Arkansas; born near Richmond, L...\n",
       "8334          J000153  A Representative from Ohio; born near Dunganno...\n",
       "10174         P000015  A Representative from Rhode Island; born in Gl...\n",
       "948           D000030  A Senator from Missouri; born in St. Louis, St...\n",
       "2687          G000423  A Representative from Kentucky; born in 1818; ...\n",
       "8346          V000118  A Representative from California; born in Otta..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_number = 10\n",
    "bio_sample = df.sample(n=sample_number, random_state=456)\n",
    "bio_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84080ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Representative from New York; born in Charlton, Saratoga County, N.Y., in 1800; attended the public schools, and was graduated from Union College, Schenectady, N.Y., in 1819; studied law; was admitted to the bar and commenced practice in Ballston Spa; one of the first directors of the Ballston Spa State Bank (later the Ballston Spa National Bank), which was organized in 1830; elected as a Whig to the Twenty-sixth Congress and served from March 4, 1839, until his death in Ballston Spa, N.Y., June 14, 1840; interment in the cemetery of the Ballston Spa Cemetery Association.\\n\\n###\\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_sample['profileText'].to_list()[2]\n",
    "bio_sample['profileText'].to_list()[2] + '\\n\\n###\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fab97b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7BynSTSeZKp9xDRDIe7lVwP06AUEZ at 0x7fd1419bc180> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Time period | Location\\n--- | ---\\n1820-1830 | Schenectady, N.Y.\\n1830-1850 | Ballston Spa, N.Y.\\n1850-1855 | New York City\\n###\\n### | Saratoga Springs, New York\\n### | Charlton, Saratoga County, N.Y.\\n### | Charlton, N.Y.\\n### | Saratoga Springs, New York\\n### | Charlton, Saratoga County, N.Y.\\n### | Saratoga Springs, New York\\n### | Charlton, Saratoga County, N.Y.\\n### | Saratoga Springs, New York\\n### | Charlton, Saratoga County, N.Y.\\n### | Saratoga Springs, New York\\n### | Charlton, Saratoga County, N.Y.\\n### | Saratoga Springs, New York\\n### | Charlton, Saratoga County, N.Y.\\n### | Saratoga Springs, New York\\n### | Charlton, Saratoga County, N.Y.\\n### | Saratoga Springs, New York\\n### | Charlton, Saratoga County, N.Y.\\n### | Charlton, Saratoga County, N.Y.\\n### | Saratoga Springs, New York\\n### | Charlton, Saratoga County, N.Y\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683089666,\n",
       "  \"id\": \"cmpl-7BynSTSeZKp9xDRDIe7lVwP06AUEZ\",\n",
       "  \"model\": \"ada:ft-personal-2023-05-03-04-47-09\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 300,\n",
       "    \"prompt_tokens\": 146,\n",
       "    \"total_tokens\": 446\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = openai.Completion.create(\n",
    "    model=ft_model, \n",
    "    prompt= bio_sample['profileText'].to_list()[2] + '\\n\\n###\\n\\n',\n",
    "    max_tokens = 300\n",
    "    )\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ce104f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7BzV2ErJlHzCBcVVeN3Y2lNRBgt9y at 0x7fd14275c9a0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"I know these should be in a similar format - time, locationI was thinking of combining this and creating a similar sentence as an output sentence. Could I just consolidate it in a single sentence?\\n\\n\\n\\npul4sergeant Data Dumping Expert\\n\\nUSA\\n\\n32700 Posts Posted - 07/01/2011 : 01:40:56\\n\\n\\n\\nCreate the relevent fields\\n\\n\\n\\nLookup\\n\\nStatus is not self-explanatory, but it indicates that the volunteer has given up their driver\\u00e2\\u20ac\\u2122s liscence.\\n\\n\\n\\nIndex\\n\\nYou would need to create an index for the Name field if you needed to add/remove volunteers quickly\\n\\n\\n\\nCalendar\\n\\nLets you easily jump to months/years/dates. This can be particularly useful, if you need to take up the role of lead volunteer coordinator, but need to know who you are reporting to on your first day\\n\\n\\n\\n\\n\\nSome useful calculated fields that I have used:\\n\\n\\n\\nFrom_Month - Returns the the 1st day of the month, or the search release or it could be\\n\\n\\n\\nMonth+1\\n\\nCreate Calculated Field \\u00e2\\u20ac\\u201c Name \\u00e2\\u20ac\\u201c From Month\\n\\nWhere: \\u00e2\\u20ac\\u201c Rank()>0\\n\\n\\n\\n\\n\\nSimilar Used when volunteers needed to know who was above them in the chain of command. A Lead Volunteer was responsible for the volunteers that reported to\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683092368,\n",
       "  \"id\": \"cmpl-7BzV2ErJlHzCBcVVeN3Y2lNRBgt9y\",\n",
       "  \"model\": \"davinci\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 300,\n",
       "    \"prompt_tokens\": 215,\n",
       "    \"total_tokens\": 515\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = openai.Completion.create(\n",
    "    model=\"davinci\", \n",
    "    prompt= prompt_pre + bio_sample['profileText'].to_list()[2],\n",
    "    max_tokens = 300\n",
    "    )\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ee1664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caching\n",
    "redis_client = redis.Redis(host = 'localhost', port = 6379, db = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da8349dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_table(id, bio, update=None):\n",
    "    \"\"\"\n",
    "    Takes in a bio, let chatGPT generate the table, and outputs the table\n",
    "    \"\"\"\n",
    "    table_key = f\"politician_{id}\"\n",
    "    table = redis_client.get(table_key)\n",
    "\n",
    "    if update:\n",
    "        table = None\n",
    "\n",
    "    if not table:\n",
    "        print('Could not find table in cache. Retrieving from Chat GPT API...')\n",
    "        prompt = prompt_pre + bio\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model='gpt-3.5-turbo', \n",
    "            messages=[{'role':'user', 'content': prompt}]\n",
    "        )\n",
    "\n",
    "        table = completion.choices[0].message.content\n",
    "        redis_client.set(table_key, json.dumps(table))\n",
    "    \n",
    "    else:\n",
    "        print('Found table in cache, serving from redis...')\n",
    "        table = json.loads(table)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42602cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo', \n",
    "    prompt=\n",
    ")\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646bf0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/bioguide.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25f90fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df.usCongressBioId.tolist()\n",
    "sample_ids = random.sample(ids, 10)\n",
    "sample_bios = [df.loc[df['usCongressBioId'] == id].iloc[0]['profileText'] for id in sample_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abf6da41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find table in cache. Retrieving from Chat GPT API...\n",
      "Could not find table in cache. Retrieving from Chat GPT API...\n",
      "Could not find table in cache. Retrieving from Chat GPT API...\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for default-gpt-3.5-turbo in organization org-vKCBEQVe239NujuUA2Vob8sR on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6b/l8cgp_y91pz6_17n81klfkw80000gn/T/ipykernel_67324/3001629698.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_bios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6b/l8cgp_y91pz6_17n81klfkw80000gn/T/ipykernel_67324/3611721132.py\u001b[0m in \u001b[0;36mgen_table\u001b[0;34m(id, bio, update)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not find table in cache. Retrieving from Chat GPT API...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_pre\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         completion = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpt-3.5-turbo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'role'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'content'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             return (\n\u001b[0;32m--> 620\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    621\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    684\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for default-gpt-3.5-turbo in organization org-vKCBEQVe239NujuUA2Vob8sR on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
     ]
    }
   ],
   "source": [
    "tables = []\n",
    "for i in range(len(sample_ids)):\n",
    "    table = gen_table(sample_ids[i], sample_bios[i])\n",
    "    tables.append(table)\n",
    "\n",
    "for table in tables:\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1daad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ''\n",
    "for i in range(len(tables)):\n",
    "    sample += sample_ids[i] + '\\n'\n",
    "    sample += sample_bios[i] + '\\n'\n",
    "    sample += tables[i] + '\\n'\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08607517",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sampletables.txt', 'w') as f:\n",
    "    f.write(sample)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "526a3113e883f61beef86ede594754d8bd591cb31b4b3261c1dfaa691314bdad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
